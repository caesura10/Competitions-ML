{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np1\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_file.csv')\n",
    "test = pd.read_csv('test_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"MaterialType\"] = data['MaterialType'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['UsageClass','CheckoutType','CheckoutYear','CheckoutMonth','ID'],inplace=True,axis=1)\n",
    "test.drop(['UsageClass','CheckoutType','CheckoutYear','CheckoutMonth'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"MaterialType\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(lambda x: x.astype(str).str.lower())\n",
    "test = test.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Title\"] = data['Title'].str.replace('[^\\w\\s]','')\n",
    "test[\"Title\"] = test['Title'].str.replace('[^\\w\\s]','')\n",
    "data[\"Creator\"] = data['Creator'].str.replace('[^\\w\\s]','')\n",
    "data[\"Subjects\"] = data['Subjects'].str.replace('[^\\w\\s]','')\n",
    "##data[\"Subjects\"] = data['Subjects'].str.replace('[0-9]','')\n",
    "data[\"Publisher\"] = data['Publisher'].str.replace('[^\\w\\s]','')\n",
    "data[\"PublicationYear\"] = data['PublicationYear'].str.replace('[^\\w\\s]','')\n",
    "data[\"PublicationYear\"] = data['PublicationYear'].str.replace('[cp]','')\n",
    "data[\"Creator\"] = data['Creator'].str.replace('[0-9]','')\n",
    "test[\"Subjects\"] = test['Subjects'].str.replace('[^\\w\\s]','')\n",
    "##test[\"Subjects\"] = test['Subjects'].str.replace('[0-9]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Checkouts</th>\n",
       "      <th>Title</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>PublicationYear</th>\n",
       "      <th>MaterialType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tidal wave</td>\n",
       "      <td>nan</td>\n",
       "      <td>tsunamis tsunamis juvenile literature</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>london holiday  richard peck</td>\n",
       "      <td>peck richard</td>\n",
       "      <td>nan</td>\n",
       "      <td>viking</td>\n",
       "      <td>1998</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>cinco de mayo  celebrating hispanic pride  car...</td>\n",
       "      <td>gnojewski carol</td>\n",
       "      <td>cinco de mayo mexican holiday history juvenile...</td>\n",
       "      <td>enslow publishers</td>\n",
       "      <td>2002</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>annapolis</td>\n",
       "      <td>nan</td>\n",
       "      <td>war stories historical fiction domestic fictio...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>as a man thinketh</td>\n",
       "      <td>nan</td>\n",
       "      <td>thought and thinking</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Checkouts                                              Title  \\\n",
       "0         1                                         tidal wave   \n",
       "1         1                       london holiday  richard peck   \n",
       "2         3  cinco de mayo  celebrating hispanic pride  car...   \n",
       "3         1                                          annapolis   \n",
       "4         1                                  as a man thinketh   \n",
       "\n",
       "           Creator                                           Subjects  \\\n",
       "0              nan              tsunamis tsunamis juvenile literature   \n",
       "1    peck richard                                                 nan   \n",
       "2  gnojewski carol  cinco de mayo mexican holiday history juvenile...   \n",
       "3              nan  war stories historical fiction domestic fictio...   \n",
       "4              nan                               thought and thinking   \n",
       "\n",
       "           Publisher PublicationYear MaterialType  \n",
       "0                nan             nan         book  \n",
       "1             viking            1998         book  \n",
       "2  enslow publishers            2002         book  \n",
       "3                nan             nan         book  \n",
       "4                nan             nan         book  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Checkouts</th>\n",
       "      <th>Title</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>PublicationYear</th>\n",
       "      <th>MaterialType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31603</th>\n",
       "      <td>6</td>\n",
       "      <td>priscilla and the pink planet</td>\n",
       "      <td>nan</td>\n",
       "      <td>stories in rhyme pink fiction</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31604</th>\n",
       "      <td>1</td>\n",
       "      <td>hurricane bay</td>\n",
       "      <td>nan</td>\n",
       "      <td>romantic suspense fiction large type books man...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31605</th>\n",
       "      <td>1</td>\n",
       "      <td>barashek kotoryi poterialsia</td>\n",
       "      <td>nan</td>\n",
       "      <td>russian language materials sheep fiction</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31606</th>\n",
       "      <td>5</td>\n",
       "      <td>shangriladeeda sound recording  stone temple p...</td>\n",
       "      <td>stone temple pilots musical group</td>\n",
       "      <td>rock music 2001 2010</td>\n",
       "      <td>atlantic</td>\n",
       "      <td>2001</td>\n",
       "      <td>sounddisc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31607</th>\n",
       "      <td>1</td>\n",
       "      <td>perfect wedding cake</td>\n",
       "      <td>nan</td>\n",
       "      <td>wedding cakes cake decorating</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31608</th>\n",
       "      <td>1</td>\n",
       "      <td>the little black hen  antony pogorelsky  illus...</td>\n",
       "      <td>james elizabeth</td>\n",
       "      <td>chickens folklore folklore russia federation j...</td>\n",
       "      <td>simply read books</td>\n",
       "      <td>2003</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31609</th>\n",
       "      <td>2</td>\n",
       "      <td>yellow stories</td>\n",
       "      <td>nan</td>\n",
       "      <td>asian americans fiction california social life...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31610</th>\n",
       "      <td>2</td>\n",
       "      <td>journey</td>\n",
       "      <td>nan</td>\n",
       "      <td>science fiction metamorphosis juvenile fiction</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31611</th>\n",
       "      <td>2</td>\n",
       "      <td>cezanne three colours cezanne</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>videodisc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31612</th>\n",
       "      <td>1</td>\n",
       "      <td>make yourself a monster a book of creepy crafts</td>\n",
       "      <td>nan</td>\n",
       "      <td>handicraft handicraft juvenile literature mons...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31613</th>\n",
       "      <td>4</td>\n",
       "      <td>unlucky in law</td>\n",
       "      <td>nan</td>\n",
       "      <td>legal stories mystery fiction women lawyers fi...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31614</th>\n",
       "      <td>1</td>\n",
       "      <td>outlaw culture resisting representations</td>\n",
       "      <td>nan</td>\n",
       "      <td>african americans intellectual life united sta...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31615</th>\n",
       "      <td>1</td>\n",
       "      <td>urban etiquette marvelous manners for the mode...</td>\n",
       "      <td>nan</td>\n",
       "      <td>etiquette</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31616</th>\n",
       "      <td>1</td>\n",
       "      <td>upholstery basics</td>\n",
       "      <td>nan</td>\n",
       "      <td>upholstery upholstered furniture</td>\n",
       "      <td>cowles creative publ</td>\n",
       "      <td>1997</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31617</th>\n",
       "      <td>1</td>\n",
       "      <td>athletes guide to sponsorship how to find an i...</td>\n",
       "      <td>nan</td>\n",
       "      <td>sports sponsorship sports marketing</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31618</th>\n",
       "      <td>1</td>\n",
       "      <td>orchid biology reviews and perspectives</td>\n",
       "      <td>nan</td>\n",
       "      <td>orchids orchid culture</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31619</th>\n",
       "      <td>6</td>\n",
       "      <td>how the west was won</td>\n",
       "      <td>nan</td>\n",
       "      <td>western films video recordings for the hearing...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>videodisc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31620</th>\n",
       "      <td>1</td>\n",
       "      <td>t rex and deadly dinosaurs</td>\n",
       "      <td>nan</td>\n",
       "      <td>prehistoric animals dinosaurs dinosaurs juveni...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31621</th>\n",
       "      <td>3</td>\n",
       "      <td>jungle fever</td>\n",
       "      <td>nan</td>\n",
       "      <td>video recordings for the hearing impaired feat...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>videocass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31622</th>\n",
       "      <td>1</td>\n",
       "      <td>build amazing animals from bricks you have at ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>lego toys juvenile literature</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31623</th>\n",
       "      <td>1</td>\n",
       "      <td>collected stories  gabriel garcía márquez  tra...</td>\n",
       "      <td>garcía márquez gabriel</td>\n",
       "      <td>garca m rquez gabriel 1928 translations into e...</td>\n",
       "      <td>harpercollins publishers</td>\n",
       "      <td>1999</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31624</th>\n",
       "      <td>1</td>\n",
       "      <td>hallelujah the welcome table a lifetime of mem...</td>\n",
       "      <td>nan</td>\n",
       "      <td>cookery american angelou maya anecdotes</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>soundcass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31625</th>\n",
       "      <td>3</td>\n",
       "      <td>the fabulous sylvester  the legend the music t...</td>\n",
       "      <td>gamson joshua</td>\n",
       "      <td>sylvester 1947 1988 singers united states biog...</td>\n",
       "      <td>h holt</td>\n",
       "      <td>2005</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31626</th>\n",
       "      <td>10</td>\n",
       "      <td>the art of mending  a novel  elizabeth berg</td>\n",
       "      <td>berg elizabeth</td>\n",
       "      <td>brothers and sisters fiction repression psycho...</td>\n",
       "      <td>random house</td>\n",
       "      <td>2004</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31627</th>\n",
       "      <td>1</td>\n",
       "      <td>spies a narrative encyclopedia of dirty deeds ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>spies biography espionage encyclopedias intell...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31628</th>\n",
       "      <td>1</td>\n",
       "      <td>the sonnets  william shakespeare  illustrated ...</td>\n",
       "      <td>shakespeare william</td>\n",
       "      <td>sonnets english</td>\n",
       "      <td>little brown</td>\n",
       "      <td>1998</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31629</th>\n",
       "      <td>23</td>\n",
       "      <td>melancholy baby  robert b parker</td>\n",
       "      <td>parker robert b</td>\n",
       "      <td>randall sunny fictitious character fiction wom...</td>\n",
       "      <td>putnam</td>\n",
       "      <td>2004</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31630</th>\n",
       "      <td>1</td>\n",
       "      <td>adam draws himself a dragon</td>\n",
       "      <td>nan</td>\n",
       "      <td>schools fiction dragons fiction self actualiza...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31631</th>\n",
       "      <td>1</td>\n",
       "      <td>test your punctuation</td>\n",
       "      <td>nan</td>\n",
       "      <td>english language punctuation juvenile literature</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31632</th>\n",
       "      <td>1</td>\n",
       "      <td>return to the battle of normandy june 1944 an ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>levy marvin diaries world war 1939 1945 campai...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>videocass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31633</th>\n",
       "      <td>1</td>\n",
       "      <td>are study guide multiple choice divisions</td>\n",
       "      <td>nan</td>\n",
       "      <td>architecture united states examinations study ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31634</th>\n",
       "      <td>1</td>\n",
       "      <td>third watch</td>\n",
       "      <td>nan</td>\n",
       "      <td>christian fiction biographical fiction jesus c...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31635</th>\n",
       "      <td>1</td>\n",
       "      <td>weigh dead an iris house bb mystery</td>\n",
       "      <td>nan</td>\n",
       "      <td>large type books mystery fiction missouri fict...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31636</th>\n",
       "      <td>1</td>\n",
       "      <td>israel arab reader a documentary history of th...</td>\n",
       "      <td>nan</td>\n",
       "      <td>arab israeli conflict sources</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31637</th>\n",
       "      <td>1</td>\n",
       "      <td>the criminal justice system in washington stat...</td>\n",
       "      <td>aos steven</td>\n",
       "      <td>criminal justice administration of washington ...</td>\n",
       "      <td>washington state institute for public policy</td>\n",
       "      <td>2003</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31638</th>\n",
       "      <td>7</td>\n",
       "      <td>cover girl</td>\n",
       "      <td>nan</td>\n",
       "      <td>video recordings for the hearing impaired feat...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>videodisc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31639</th>\n",
       "      <td>1</td>\n",
       "      <td>so youve got a great idea</td>\n",
       "      <td>nan</td>\n",
       "      <td>new business enterprises</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>soundcass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31640</th>\n",
       "      <td>3</td>\n",
       "      <td>lionel at school  by stephen krensky  pictures...</td>\n",
       "      <td>krensky stephen</td>\n",
       "      <td>schools fiction</td>\n",
       "      <td>dial books for young readers</td>\n",
       "      <td>2000</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31641</th>\n",
       "      <td>2</td>\n",
       "      <td>fall of fergal or not so dingly in the dell</td>\n",
       "      <td>nan</td>\n",
       "      <td>humorous stories brothers and sisters fiction ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31642</th>\n",
       "      <td>1</td>\n",
       "      <td>sabbaths theater</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31643</th>\n",
       "      <td>4</td>\n",
       "      <td>living dead in dallas  charlaine harris</td>\n",
       "      <td>harris charlaine</td>\n",
       "      <td>stackhouse sookie fictitious character fiction...</td>\n",
       "      <td>ace books  berkley pub group</td>\n",
       "      <td>2002</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31644</th>\n",
       "      <td>3</td>\n",
       "      <td>witchs hand</td>\n",
       "      <td>nan</td>\n",
       "      <td>witches fiction</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31645</th>\n",
       "      <td>1</td>\n",
       "      <td>flower of sheba</td>\n",
       "      <td>nan</td>\n",
       "      <td>solomon king of israel jews folklore solomon k...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31646</th>\n",
       "      <td>6</td>\n",
       "      <td>licence to kill</td>\n",
       "      <td>nan</td>\n",
       "      <td>video recordings for the hearing impaired jame...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>videocass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31647</th>\n",
       "      <td>1</td>\n",
       "      <td>naturally healthy hair herbal treatments and d...</td>\n",
       "      <td>nan</td>\n",
       "      <td>medicine ayurvedic hair preparations hair care...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31648</th>\n",
       "      <td>2</td>\n",
       "      <td>california camping</td>\n",
       "      <td>nan</td>\n",
       "      <td>california guidebooks camp sites facilities et...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31649</th>\n",
       "      <td>5</td>\n",
       "      <td>silent world of nicholas quinn</td>\n",
       "      <td>nan</td>\n",
       "      <td>morse inspector fictitious character drama</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>videocass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31650</th>\n",
       "      <td>12</td>\n",
       "      <td>big lebowski</td>\n",
       "      <td>nan</td>\n",
       "      <td>video recordings for the hearing impaired feat...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>videodisc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31651</th>\n",
       "      <td>4</td>\n",
       "      <td>fables 3 storybook love  bill willingham write...</td>\n",
       "      <td>willingham bill</td>\n",
       "      <td>fairy tales comic books strips etc graphic nov...</td>\n",
       "      <td>dc comics</td>\n",
       "      <td>2004</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31652</th>\n",
       "      <td>2</td>\n",
       "      <td>illm higher command</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Checkouts                                              Title  \\\n",
       "31603         6                      priscilla and the pink planet   \n",
       "31604         1                                      hurricane bay   \n",
       "31605         1                       barashek kotoryi poterialsia   \n",
       "31606         5  shangriladeeda sound recording  stone temple p...   \n",
       "31607         1                               perfect wedding cake   \n",
       "31608         1  the little black hen  antony pogorelsky  illus...   \n",
       "31609         2                                     yellow stories   \n",
       "31610         2                                            journey   \n",
       "31611         2                      cezanne three colours cezanne   \n",
       "31612         1    make yourself a monster a book of creepy crafts   \n",
       "31613         4                                     unlucky in law   \n",
       "31614         1           outlaw culture resisting representations   \n",
       "31615         1  urban etiquette marvelous manners for the mode...   \n",
       "31616         1                                  upholstery basics   \n",
       "31617         1  athletes guide to sponsorship how to find an i...   \n",
       "31618         1            orchid biology reviews and perspectives   \n",
       "31619         6                               how the west was won   \n",
       "31620         1                         t rex and deadly dinosaurs   \n",
       "31621         3                                       jungle fever   \n",
       "31622         1  build amazing animals from bricks you have at ...   \n",
       "31623         1  collected stories  gabriel garcía márquez  tra...   \n",
       "31624         1  hallelujah the welcome table a lifetime of mem...   \n",
       "31625         3  the fabulous sylvester  the legend the music t...   \n",
       "31626        10        the art of mending  a novel  elizabeth berg   \n",
       "31627         1  spies a narrative encyclopedia of dirty deeds ...   \n",
       "31628         1  the sonnets  william shakespeare  illustrated ...   \n",
       "31629        23                   melancholy baby  robert b parker   \n",
       "31630         1                        adam draws himself a dragon   \n",
       "31631         1                              test your punctuation   \n",
       "31632         1  return to the battle of normandy june 1944 an ...   \n",
       "31633         1          are study guide multiple choice divisions   \n",
       "31634         1                                        third watch   \n",
       "31635         1                weigh dead an iris house bb mystery   \n",
       "31636         1  israel arab reader a documentary history of th...   \n",
       "31637         1  the criminal justice system in washington stat...   \n",
       "31638         7                                         cover girl   \n",
       "31639         1                          so youve got a great idea   \n",
       "31640         3  lionel at school  by stephen krensky  pictures...   \n",
       "31641         2        fall of fergal or not so dingly in the dell   \n",
       "31642         1                                   sabbaths theater   \n",
       "31643         4            living dead in dallas  charlaine harris   \n",
       "31644         3                                        witchs hand   \n",
       "31645         1                                    flower of sheba   \n",
       "31646         6                                    licence to kill   \n",
       "31647         1  naturally healthy hair herbal treatments and d...   \n",
       "31648         2                                 california camping   \n",
       "31649         5                     silent world of nicholas quinn   \n",
       "31650        12                                       big lebowski   \n",
       "31651         4  fables 3 storybook love  bill willingham write...   \n",
       "31652         2                                illm higher command   \n",
       "\n",
       "                                 Creator  \\\n",
       "31603                                nan   \n",
       "31604                                nan   \n",
       "31605                                nan   \n",
       "31606  stone temple pilots musical group   \n",
       "31607                                nan   \n",
       "31608                   james elizabeth    \n",
       "31609                                nan   \n",
       "31610                                nan   \n",
       "31611                                nan   \n",
       "31612                                nan   \n",
       "31613                                nan   \n",
       "31614                                nan   \n",
       "31615                                nan   \n",
       "31616                                nan   \n",
       "31617                                nan   \n",
       "31618                                nan   \n",
       "31619                                nan   \n",
       "31620                                nan   \n",
       "31621                                nan   \n",
       "31622                                nan   \n",
       "31623            garcía márquez gabriel    \n",
       "31624                                nan   \n",
       "31625                     gamson joshua    \n",
       "31626                     berg elizabeth   \n",
       "31627                                nan   \n",
       "31628               shakespeare william    \n",
       "31629                   parker robert b    \n",
       "31630                                nan   \n",
       "31631                                nan   \n",
       "31632                                nan   \n",
       "31633                                nan   \n",
       "31634                                nan   \n",
       "31635                                nan   \n",
       "31636                                nan   \n",
       "31637                         aos steven   \n",
       "31638                                nan   \n",
       "31639                                nan   \n",
       "31640                    krensky stephen   \n",
       "31641                                nan   \n",
       "31642                                nan   \n",
       "31643                   harris charlaine   \n",
       "31644                                nan   \n",
       "31645                                nan   \n",
       "31646                                nan   \n",
       "31647                                nan   \n",
       "31648                                nan   \n",
       "31649                                nan   \n",
       "31650                                nan   \n",
       "31651                    willingham bill   \n",
       "31652                                nan   \n",
       "\n",
       "                                                Subjects  \\\n",
       "31603                      stories in rhyme pink fiction   \n",
       "31604  romantic suspense fiction large type books man...   \n",
       "31605           russian language materials sheep fiction   \n",
       "31606                               rock music 2001 2010   \n",
       "31607                      wedding cakes cake decorating   \n",
       "31608  chickens folklore folklore russia federation j...   \n",
       "31609  asian americans fiction california social life...   \n",
       "31610     science fiction metamorphosis juvenile fiction   \n",
       "31611                                                nan   \n",
       "31612  handicraft handicraft juvenile literature mons...   \n",
       "31613  legal stories mystery fiction women lawyers fi...   \n",
       "31614  african americans intellectual life united sta...   \n",
       "31615                                          etiquette   \n",
       "31616                   upholstery upholstered furniture   \n",
       "31617                sports sponsorship sports marketing   \n",
       "31618                             orchids orchid culture   \n",
       "31619  western films video recordings for the hearing...   \n",
       "31620  prehistoric animals dinosaurs dinosaurs juveni...   \n",
       "31621  video recordings for the hearing impaired feat...   \n",
       "31622                      lego toys juvenile literature   \n",
       "31623  garca m rquez gabriel 1928 translations into e...   \n",
       "31624            cookery american angelou maya anecdotes   \n",
       "31625  sylvester 1947 1988 singers united states biog...   \n",
       "31626  brothers and sisters fiction repression psycho...   \n",
       "31627  spies biography espionage encyclopedias intell...   \n",
       "31628                                    sonnets english   \n",
       "31629  randall sunny fictitious character fiction wom...   \n",
       "31630  schools fiction dragons fiction self actualiza...   \n",
       "31631   english language punctuation juvenile literature   \n",
       "31632  levy marvin diaries world war 1939 1945 campai...   \n",
       "31633  architecture united states examinations study ...   \n",
       "31634  christian fiction biographical fiction jesus c...   \n",
       "31635  large type books mystery fiction missouri fict...   \n",
       "31636                      arab israeli conflict sources   \n",
       "31637  criminal justice administration of washington ...   \n",
       "31638  video recordings for the hearing impaired feat...   \n",
       "31639                           new business enterprises   \n",
       "31640                                    schools fiction   \n",
       "31641  humorous stories brothers and sisters fiction ...   \n",
       "31642                                                nan   \n",
       "31643  stackhouse sookie fictitious character fiction...   \n",
       "31644                                    witches fiction   \n",
       "31645  solomon king of israel jews folklore solomon k...   \n",
       "31646  video recordings for the hearing impaired jame...   \n",
       "31647  medicine ayurvedic hair preparations hair care...   \n",
       "31648  california guidebooks camp sites facilities et...   \n",
       "31649         morse inspector fictitious character drama   \n",
       "31650  video recordings for the hearing impaired feat...   \n",
       "31651  fairy tales comic books strips etc graphic nov...   \n",
       "31652                                                nan   \n",
       "\n",
       "                                          Publisher PublicationYear  \\\n",
       "31603                                           nan             nan   \n",
       "31604                                           nan             nan   \n",
       "31605                                           nan             nan   \n",
       "31606                                      atlantic            2001   \n",
       "31607                                           nan             nan   \n",
       "31608                             simply read books            2003   \n",
       "31609                                           nan             nan   \n",
       "31610                                           nan             nan   \n",
       "31611                                           nan             nan   \n",
       "31612                                           nan             nan   \n",
       "31613                                           nan             nan   \n",
       "31614                                           nan             nan   \n",
       "31615                                           nan             nan   \n",
       "31616                          cowles creative publ            1997   \n",
       "31617                                           nan             nan   \n",
       "31618                                           nan             nan   \n",
       "31619                                           nan             nan   \n",
       "31620                                           nan             nan   \n",
       "31621                                           nan             nan   \n",
       "31622                                           nan             nan   \n",
       "31623                      harpercollins publishers            1999   \n",
       "31624                                           nan             nan   \n",
       "31625                                        h holt            2005   \n",
       "31626                                  random house            2004   \n",
       "31627                                           nan             nan   \n",
       "31628                                  little brown            1998   \n",
       "31629                                        putnam            2004   \n",
       "31630                                           nan             nan   \n",
       "31631                                           nan             nan   \n",
       "31632                                           nan             nan   \n",
       "31633                                           nan             nan   \n",
       "31634                                           nan             nan   \n",
       "31635                                           nan             nan   \n",
       "31636                                           nan             nan   \n",
       "31637  washington state institute for public policy            2003   \n",
       "31638                                           nan             nan   \n",
       "31639                                           nan             nan   \n",
       "31640                  dial books for young readers            2000   \n",
       "31641                                           nan             nan   \n",
       "31642                                           nan             nan   \n",
       "31643                  ace books  berkley pub group            2002   \n",
       "31644                                           nan             nan   \n",
       "31645                                           nan             nan   \n",
       "31646                                           nan             nan   \n",
       "31647                                           nan             nan   \n",
       "31648                                           nan             nan   \n",
       "31649                                           nan             nan   \n",
       "31650                                           nan             nan   \n",
       "31651                                     dc comics            2004   \n",
       "31652                                           nan             nan   \n",
       "\n",
       "      MaterialType  \n",
       "31603         book  \n",
       "31604         book  \n",
       "31605         book  \n",
       "31606    sounddisc  \n",
       "31607         book  \n",
       "31608         book  \n",
       "31609         book  \n",
       "31610         book  \n",
       "31611    videodisc  \n",
       "31612         book  \n",
       "31613         book  \n",
       "31614         book  \n",
       "31615         book  \n",
       "31616         book  \n",
       "31617         book  \n",
       "31618         book  \n",
       "31619    videodisc  \n",
       "31620         book  \n",
       "31621    videocass  \n",
       "31622         book  \n",
       "31623         book  \n",
       "31624    soundcass  \n",
       "31625         book  \n",
       "31626         book  \n",
       "31627         book  \n",
       "31628         book  \n",
       "31629         book  \n",
       "31630         book  \n",
       "31631         book  \n",
       "31632    videocass  \n",
       "31633         book  \n",
       "31634         book  \n",
       "31635         book  \n",
       "31636         book  \n",
       "31637         book  \n",
       "31638    videodisc  \n",
       "31639    soundcass  \n",
       "31640         book  \n",
       "31641         book  \n",
       "31642         book  \n",
       "31643         book  \n",
       "31644         book  \n",
       "31645         book  \n",
       "31646    videocass  \n",
       "31647         book  \n",
       "31648         book  \n",
       "31649    videocass  \n",
       "31650    videodisc  \n",
       "31651         book  \n",
       "31652        mixed  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords(text):\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Title'] = data['Title'].apply(stopwords)\n",
    "data['Subjects'] = data['Subjects'].apply(stopwords)\n",
    "\n",
    "test['Subjects'] = test['Subjects'].apply(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkouts             50\n",
      "Title              31347\n",
      "Creator             6726\n",
      "Subjects           24753\n",
      "Publisher           3340\n",
      "PublicationYear      483\n",
      "MaterialType           8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from textblob import TextBlob\n",
    "#data['Subjects'].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre(data):\n",
    "    word = lemmatizer.lemmatize(data) \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Title'] = data['Title'].apply(pre)\n",
    "data['Subjects'] = data['Subjects'].apply(pre)\n",
    "test['Subjects'] = test['Subjects'].apply(pre)\n",
    "test['Title'] = test['Title'].apply(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkouts             50\n",
      "Title              31288\n",
      "Creator             6726\n",
      "Subjects           24750\n",
      "Publisher           3340\n",
      "PublicationYear      483\n",
      "MaterialType           8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Subjects\"] = data['Subjects'].replace('nan','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Checkouts</th>\n",
       "      <th>Title</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>PublicationYear</th>\n",
       "      <th>MaterialType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tidal wave</td>\n",
       "      <td>nan</td>\n",
       "      <td>tsunamis tsunamis juvenile literature</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>london holiday richard peck</td>\n",
       "      <td>peck richard</td>\n",
       "      <td></td>\n",
       "      <td>viking</td>\n",
       "      <td>1998</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>cinco de mayo celebrating hispanic pride carol...</td>\n",
       "      <td>gnojewski carol</td>\n",
       "      <td>cinco de mayo mexican holiday history juvenile...</td>\n",
       "      <td>enslow publishers</td>\n",
       "      <td>2002</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>annapolis</td>\n",
       "      <td>nan</td>\n",
       "      <td>war stories historical fiction domestic fictio...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>man thinketh</td>\n",
       "      <td>nan</td>\n",
       "      <td>thought thinking</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Checkouts                                              Title  \\\n",
       "0         1                                         tidal wave   \n",
       "1         1                        london holiday richard peck   \n",
       "2         3  cinco de mayo celebrating hispanic pride carol...   \n",
       "3         1                                          annapolis   \n",
       "4         1                                       man thinketh   \n",
       "\n",
       "           Creator                                           Subjects  \\\n",
       "0              nan              tsunamis tsunamis juvenile literature   \n",
       "1    peck richard                                                       \n",
       "2  gnojewski carol  cinco de mayo mexican holiday history juvenile...   \n",
       "3              nan  war stories historical fiction domestic fictio...   \n",
       "4              nan                                   thought thinking   \n",
       "\n",
       "           Publisher PublicationYear MaterialType  \n",
       "0                nan             nan         book  \n",
       "1             viking            1998         book  \n",
       "2  enslow publishers            2002         book  \n",
       "3                nan             nan         book  \n",
       "4                nan             nan         book  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Final\"] = data[\"Title\"].map(str) + ' ' + data[\"Subjects\"] \n",
    "test[\"Final\"] = test[\"Title\"].map(str) + ' ' + test[\"Subjects\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Checkouts</th>\n",
       "      <th>Title</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>PublicationYear</th>\n",
       "      <th>MaterialType</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tidal wave</td>\n",
       "      <td>nan</td>\n",
       "      <td>tsunamis tsunamis juvenile literature</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "      <td>tidal wave tsunamis tsunamis juvenile literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>london holiday richard peck</td>\n",
       "      <td>peck richard</td>\n",
       "      <td></td>\n",
       "      <td>viking</td>\n",
       "      <td>1998</td>\n",
       "      <td>book</td>\n",
       "      <td>london holiday richard peck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>cinco de mayo celebrating hispanic pride carol...</td>\n",
       "      <td>gnojewski carol</td>\n",
       "      <td>cinco de mayo mexican holiday history juvenile...</td>\n",
       "      <td>enslow publishers</td>\n",
       "      <td>2002</td>\n",
       "      <td>book</td>\n",
       "      <td>cinco de mayo celebrating hispanic pride carol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>annapolis</td>\n",
       "      <td>nan</td>\n",
       "      <td>war stories historical fiction domestic fictio...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "      <td>annapolis war stories historical fiction domes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>man thinketh</td>\n",
       "      <td>nan</td>\n",
       "      <td>thought thinking</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>book</td>\n",
       "      <td>man thinketh thought thinking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Checkouts                                              Title  \\\n",
       "0         1                                         tidal wave   \n",
       "1         1                        london holiday richard peck   \n",
       "2         3  cinco de mayo celebrating hispanic pride carol...   \n",
       "3         1                                          annapolis   \n",
       "4         1                                       man thinketh   \n",
       "\n",
       "           Creator                                           Subjects  \\\n",
       "0              nan              tsunamis tsunamis juvenile literature   \n",
       "1    peck richard                                                       \n",
       "2  gnojewski carol  cinco de mayo mexican holiday history juvenile...   \n",
       "3              nan  war stories historical fiction domestic fictio...   \n",
       "4              nan                                   thought thinking   \n",
       "\n",
       "           Publisher PublicationYear MaterialType  \\\n",
       "0                nan             nan         book   \n",
       "1             viking            1998         book   \n",
       "2  enslow publishers            2002         book   \n",
       "3                nan             nan         book   \n",
       "4                nan             nan         book   \n",
       "\n",
       "                                               Final  \n",
       "0   tidal wave tsunamis tsunamis juvenile literature  \n",
       "1                       london holiday richard peck   \n",
       "2  cinco de mayo celebrating hispanic pride carol...  \n",
       "3  annapolis war stories historical fiction domes...  \n",
       "4                      man thinketh thought thinking  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns = ['MaterialType']\n",
    "\n",
    "#def encoder(df):\n",
    "    for col in columns:\n",
    "        label_encoder = LabelEncoder()\n",
    "        label_encoder.fit(df[col])\n",
    "        df[col] = label_encoder.transform(df[col])\n",
    "    return df\n",
    "\n",
    "data = encoder(data)\n",
    "test = encoder(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['Final']\n",
    "w = test['Final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = vectorizer.transform(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (31653, 31097)\n",
      "Amount of Non-Zero occurrences:  327380\n",
      "Density: 0.03325973410737303\n"
     ]
    }
   ],
   "source": [
    "X = vectorizer.transform(x)\n",
    "print('Shape of Sparse Matrix: ', X.shape)\n",
    "print('Amount of Non-Zero occurrences: ', X.nnz)\n",
    "# Percentage of non-zero values\n",
    "density = (100.0 * X.nnz / (X.shape[0] * X.shape[1]))\n",
    "print('Density: {}'.format((density)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BOOK       0.96      1.00      0.98        24\n",
      "   SOUNDDISC       1.00      1.00      1.00         4\n",
      "   VIDEOCASS       0.50      0.50      0.50         2\n",
      "   VIDEODISC       1.00      0.50      0.67         2\n",
      "\n",
      "   micro avg       0.94      0.94      0.94        32\n",
      "   macro avg       0.86      0.75      0.79        32\n",
      "weighted avg       0.94      0.94      0.93        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=100)\n",
    "rfc = RandomForestClassifier(min_samples_split = 10, n_estimators = 200, verbose = 1, n_jobs = -1,warm_start = True)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Testing the model\n",
    "predictions = rfc.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbms Accuracy:  0.9375\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"lgbms Accuracy: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "pred = rfc.predict(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"ID\": test[\"ID\"],\n",
    "        \"MaterialType\": pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission21.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
